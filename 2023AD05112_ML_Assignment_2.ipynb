{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dddbad63-2fec-4cdd-9e44-14c833833ab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nM.Tech (AIML/ DSE)\\nMachine Learning\\nAssignment - 2\\n\\nName    : B.RAJASEKARAN\\nBITS ID : 2023AD05112\\nEmail   : 2023ad05112@wilp.bits-pilani.ac.in\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "M.Tech (AIML/ DSE)\n",
    "Machine Learning\n",
    "Assignment - 2\n",
    "\n",
    "Name    : B.RAJASEKARAN\n",
    "BITS ID : 2023AD05112\n",
    "Email   : 2023ad05112@wilp.bits-pilani.ac.in\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cea3125a-d3ac-4f35-8016-303305d52e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nStep 2: Machine Learning Classification models and Evaluation metrics\\nImplement the following classification models using the dataset chosen above. All\\nthe 6 ML models have to be implemented on the same dataset.\\n1. Logistic Regression\\n2. Decision Tree Classifier\\n3. K-Nearest Neighbor Classifier\\n4. Naive Bayes Classifier - Gaussian or Multinomial\\n5. Ensemble Model - Random Forest\\n6. Ensemble Model - XGBoost \\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Step 2: Machine Learning Classification models and Evaluation metrics\n",
    "Implement the following classification models using the dataset chosen above. All\n",
    "the 6 ML models have to be implemented on the same dataset.\n",
    "1. Logistic Regression\n",
    "2. Decision Tree Classifier\n",
    "3. K-Nearest Neighbor Classifier\n",
    "4. Naive Bayes Classifier - Gaussian or Multinomial\n",
    "5. Ensemble Model - Random Forest\n",
    "6. Ensemble Model - XGBoost \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416dffd1-5406-4094-8df3-9020e514e4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-learn) (3.6.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from xgboost) (2.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\admin\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from xgboost) (1.16.1)\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Importing required models\n",
    "'''\n",
    "!pip install scikit-learn\n",
    "!pip install xgboost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "'''\n",
    "Importing packages to load ML models\n",
    "1. Logistic Regression\n",
    "2. Decision Tree Classifier\n",
    "3. K-Nearest Neighbor Classifier\n",
    "4. Naive Bayes Classifier - Gaussian or Multinomial\n",
    "5. Ensemble Model - Random Forest\n",
    "6. Ensemble Model - XGBoost \n",
    "'''\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Preprocessing & Evaluation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_auc_score, matthews_corrcoef\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f77e3ab-2b3c-452a-a3f5-2a3b2bf37897",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -----------------------------\n",
    "# Load Dataset\n",
    "# -----------------------------\n",
    "df = pd.read_csv(r\"C:\\Users\\admin\\OneDrive\\Desktop\\ML_assignment\\kepler_exoplanet_search_results.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68dcbc19-9d0a-466a-804a-182e48205913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target column\n",
    "y = df[\"koi_disposition\"]   # CONFIRMED / FALSE POSITIVE / CANDIDATE\n",
    "X = df.drop(columns=[\"koi_disposition\"])\n",
    "\n",
    "# -----------------------------\n",
    "# Drop columns with all missing values\n",
    "# -----------------------------\n",
    "X = X.dropna(axis=1, how=\"all\")\n",
    "\n",
    "# Separate numeric and categorical columns\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "categorical_cols = X.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Impute numeric with mean\n",
    "num_imputer = SimpleImputer(strategy=\"mean\")\n",
    "X[numeric_cols] = num_imputer.fit_transform(X[numeric_cols])\n",
    "\n",
    "# Impute categorical with most frequent\n",
    "if len(categorical_cols) > 0:\n",
    "    cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "    X[categorical_cols] = cat_imputer.fit_transform(X[categorical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce655a67-a465-4c30-9149-d339baf8874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Encode categorical features if any\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "# Encode target labels\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# -----------------------------\n",
    "# Train-Test Split\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features (important for Logistic Regression, KNN)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac381787-a92c-4791-a8f8-3dd7cd0d30c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "All the 6 ML models have to be implemented on the same dataset.\n",
    "'''\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight=\"balanced\"),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(class_weight=\"balanced\"),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, class_weight=\"balanced\"),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric=\"mlogloss\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca777e56-9ac6-4631-9381-e9807933ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "''' \n",
    "-----------------------------------------------\n",
    "Train the models with same dataset and Evaluate\n",
    "-----------------------------------------------\n",
    "'''\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # For AUC, need probability estimates\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_proba = model.predict_proba(X_test)\n",
    "        try:\n",
    "            auc = roc_auc_score(y_test, y_proba, multi_class=\"ovr\")\n",
    "        except:\n",
    "            auc = None\n",
    "    else:\n",
    "        auc = None\n",
    "    results[name] = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"AUC Score\": auc,\n",
    "        \"Precision\": precision_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"Recall\": recall_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"F1-Score\": f1_score(y_test, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"MCC\": matthews_corrcoef(y_test, y_pred),\n",
    "        # \"Confusion Matrix\": confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b496f12-b763-4bd6-9341-5fec36a571dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFor each of the models above, calculate the following evaluation metrics:\\n1. Accuracy\\n2. AUC Score\\n3. Precision\\n4. Recall\\n5. F1 Score\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "For each of the models above, calculate the following evaluation metrics:\n",
    "1. Accuracy\n",
    "2. AUC Score\n",
    "3. Precision\n",
    "4. Recall\n",
    "5. F1 Score\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcf6fe36-4d77-44c8-82af-b25544d552c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(results)\n",
    "\n",
    "# print(\"-------------------------------------\")\n",
    "# print(\"Evaluation Metrics Summary\") \n",
    "# print(\"-------------------------------------\\n\")\n",
    "#print(summary.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f278b880-42b1-4bdd-a66f-f4ee2b415227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------\n",
      "Evaluation Metrics Summary\n",
      "-------------------------------------\n",
      "\n",
      "                     Accuracy  AUC Score  Precision  Recall  F1 Score     MCC\n",
      "Model                                                                        \n",
      "Logistic Regression    0.7998     0.9611     0.8012  0.7216    0.6715  0.7126\n",
      "Decision Tree          0.9012     0.9085     0.8645  0.8615    0.8626  0.8383\n",
      "KNN                    0.7491     0.7754     0.4905  0.6564    0.5457  0.6543\n",
      "Naive Bayes            0.3215     0.5548     0.5033  0.3919    0.3167  0.1025\n",
      "Random Forest          0.9022     0.9771     0.8736  0.8625    0.8676  0.8391\n",
      "XGBoost                0.9237     0.9821     0.8959  0.8935    0.8943  0.8752\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Build summary table with only required metrics\n",
    "summary_data = []\n",
    "for model, metrics in results.items():\n",
    "    summary_data.append({\n",
    "        \"Model\": model,\n",
    "        \"Accuracy\": metrics[\"Accuracy\"],\n",
    "        \"AUC Score\": metrics[\"AUC Score\"],\n",
    "        \"Precision\": metrics[\"Precision\"],\n",
    "        \"Recall\": metrics[\"Recall\"],\n",
    "        \"F1 Score\": metrics[\"F1-Score\"],\n",
    "        \"MCC\": metrics[\"MCC\"]\n",
    "    })\n",
    "\n",
    "# Convert to DataFrame\n",
    "summary = pd.DataFrame(summary_data)\n",
    "\n",
    "# Set model names as index\n",
    "summary.set_index(\"Model\", inplace=True)\n",
    "\n",
    "# Display neatly\n",
    "print(\"-------------------------------------\")\n",
    "print(\"Evaluation Metrics Summary\") \n",
    "print(\"-------------------------------------\\n\")\n",
    "print(summary.round(4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc7db227-cdd2-407d-84da-eccfef3c3047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/xgboost.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save trained models into the model/ folder\n",
    "joblib.dump(models[\"Logistic Regression\"], \"model/logistic_regression.pkl\")\n",
    "joblib.dump(models[\"Decision Tree\"], \"model/decision_tree.pkl\")\n",
    "joblib.dump(models[\"KNN\"], \"model/knn.pkl\")\n",
    "joblib.dump(models[\"Naive Bayes\"], \"model/naive_bayes.pkl\")\n",
    "joblib.dump(models[\"Random Forest\"], \"model/random_forest.pkl\")\n",
    "joblib.dump(models[\"XGBoost\"], \"model/xgboost.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cfdc2d90-506f-4490-b0fd-b4517c5d62aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/knn.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(models[\"KNN\"], \"model/knn.pkl\", compress=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d699df-f9f9-4b0f-a533-b1899632ad6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
